{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰 정보로드를 위한 라이브러리\n",
    "# 설치: pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 토큰 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client 생성\n",
    "\n",
    "- `client` 는 OpenAI 모듈로 생성된 인스턴스 입니다.\n",
    "\n",
    "[주의] 아래의 코드에서 오류가 난다면 API 키의 오류일 가능성이 높습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text To Speech(TTS)\n",
    "\n",
    "- TTS는 컴퓨터 프로그램이나 기기가 텍스트를 인간의 음성처럼 들리는 오디오로 변환하는 과정입니다.\n",
    "- 이 기술은 음성 합성을 통해 텍스트 데이터를 자연스러운 음성으로 바꿉니다.\n",
    "- 사용 예시: 오디오북, 음성 안내 시스템, 음성 기반 가상 어시스턴트 등.\n",
    "\n",
    "**[참고]**\n",
    "\n",
    "- 공식문서: https://platform.openai.com/docs/guides/text-to-speech\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**주요 파라미터**\n",
    "\n",
    "- `model`: 사용 가능한 TTS 모델 중 하나를 지정합니다. `tts-1` 또는 `tts-1-hd`.\n",
    "  - 최신 지원모델 확인: https://platform.openai.com/docs/models/tts\n",
    "- `input`: 오디오를 생성할 텍스트입니다. 최대 길이는 4096자입니다.\n",
    "- `voice`: 오디오를 생성할 때 사용할 음성입니다. 지원되는 음성은 `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer` 입니다. 음성의 미리듣기는 [여기](https://platform.openai.com/docs/guides/text-to-speech/voice-options) 에서 확인할 수 있습니다.\n",
    "- `response_format`: 오디오를 입력할 형식입니다. 지원되는 형식은 `mp3`, `opus`, `aac` 및 `flac` 입니다.\n",
    "- `speed`: 생성된 오디오의 속도입니다. `0.25` 에서 `4.0` 사이의 값을 선택합니다. 기본값은 `1.0` 입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_file_path = \"tts_audio.mp3\"\n",
    "\n",
    "response = client.audio.speech.create(\n",
    "    model=\"tts-1\",\n",
    "    input=\"아~ 오늘 파이썬 배우기 정말 좋은 날이네~\",\n",
    "    voice=\"shimmer\",\n",
    "    response_format=\"mp3\",\n",
    "    speed=2.0,\n",
    ")\n",
    "\n",
    "response.stream_to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저장한 오디오 파일을 재생합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "Audio(speech_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech To Text(STT)\n",
    "\n",
    "- STT는 사람의 말소리를 텍스트로 변환하는 기술입니다.\n",
    "- 이는 음성 인식을 통해 구어체 언어를 캡처하고 이를 기록 가능한 형태의 텍스트로 변환합니다.\n",
    "- 사용예시: 음성 명령 입력, 자동 회의록 작성, 음성 기반 검색 시스템 등.\n",
    "\n",
    "**[참고]**\n",
    "\n",
    "- 공식문서: https://platform.openai.com/docs/guides/speech-to-text\n",
    "- 파일 업로드는 현재 25MB로 제한되어 있으며, 지원되는 입력 파일 형식은 `mp3`, `MP4`, `MPEG`, `MPGA`, `M4A`, `WAV`, `WEBM` 입니다.\n",
    "- 지원언어\n",
    "  - 아프리칸스어, 아랍어, 아르메니아어, 아제르바이잔어, 벨라루스어, 보스니아어, 불가리아어, 카탈로니아어, 중국어, 크로아티아어, 체코어, 덴마크어, 네덜란드어, 영어, 에스토니아어, 핀란드어, 프랑스어, 갈리시아어, 독일어, 그리스어, 히브리어, 힌디어, 헝가리어, 아이슬란드어, 인도네시아어, 이탈리아어, 일본어, 인도네시아어, 칸나다어, 카자흐어, 한국어, 라트비아어, 리투아니아어, 마케도니아어, 말레이어, 마라티어, 마오리어, 네팔어, 노르웨이어, 페르시아어, 폴란드어, 포르투갈어, 루마니아어, 러시아어, 세르비아어, 슬로바키아어, 슬로베니아어, 스페인어, 스와힐리어, 스웨덴어, 타갈로그어, 타밀어, 태국어, 터키어, 우크라이나어, 우르두어, 베트남어 및 웨일스어.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**주요 파라미터**\n",
    "\n",
    "- `file`: 변환할 오디오 파일 개체(파일 이름이 아님)로, 다음 형식 중 하나입니다: `FLAC`, `MP3`, `MP4`, `MPEG`, `MPGA`, `M4A`, `OGG`, `WAV` 또는 `WEBM`.\n",
    "- `model`: 현재는 `whisper-1` 모델만 지정 가능합니다.\n",
    "- `language`: 입력 오디오의 언어입니다. 입력 언어를 ISO-639-1 형식으로 제공하면 정확도와 지연 시간이 개선됩니다.\n",
    "  - [ISO-639-1 형식](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes)\n",
    "- `prompt`: (선택 사항) 모델의 스타일을 안내하거나 이전 오디오 세그먼트를 계속하기 위한 텍스트입니다. 프롬프트는 오디오 언어와 일치해야 합니다.\n",
    "- `response_format`: 변환된 결과물 출력 형식입니다. 가능한 지정 옵션은 `json`, `text`, `srt`, `verbose_json` 또는 `vtt` 입니다.\n",
    "- `temperature`: 0에서 1 사이의 샘플링 `temperature` 입니다. 0.8과 같이 값이 높을수록 출력은 더 무작위적이고, 0.2와 같이 값이 낮을수록 출력은 더 집중적이고 결정론적입니다. 0으로 설정하면 모델은 로그 확률을 사용하여 특정 임계값에 도달할 때까지 자동으로 `temperature` 을 높입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = open(\"data/채용면접_샘플_01.wav\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "    file=audio_file,\n",
    "    model=\"whisper-1\",\n",
    "    language=\"ko\",\n",
    "    response_format=\"text\",\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과물 출력\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 더욱 긴 오디오 입력 대한 처리\n",
    "\n",
    "기본적으로 Whisper API는 **25MB 미만의 파일** 만 지원합니다.\n",
    "\n",
    "이보다 긴 오디오 파일이 있는 경우 **25MB 이하의 청크로 나누거나 압축된 오디오 형식을 사용** 해야 합니다.\n",
    "\n",
    "최상의 성능을 얻으려면 문장 중간에 오디오를 분할하면 일부 문맥이 손실될 수 있으므로 분할을 피하는 것이 좋습니다.\n",
    "\n",
    "이를 처리하는 한 가지 방법은 `PyDub` 오픈 소스 Python 패키지를 사용하여 **오디오를 분할** 하는 것입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**샘플 데이터셋(채용면접 인터뷰 데이터)**\n",
    "\n",
    "- 링크: https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=data&dataSetSn=71592\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 코드는 오디오 파일을 정해진 시간에 따라 분절하여 별도의 파일로 저장하는 코드입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "filename = \"data/채용면접_샘플_02.wav\"\n",
    "myaudio = AudioSegment.from_mp3(filename)\n",
    "\n",
    "# PyDub 는 밀리초 단위로 시간을 계산합니다.\n",
    "thirty_seconds = 1 * 30 * 1000  # (1초 * 30) * 1000\n",
    "total_milliseconds = myaudio.duration_seconds * 1000  # 전체 길이를 밀리초로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 길이를 30초로 나누어서 반복할 횟수를 계산합니다.\n",
    "total_iterations = int(total_milliseconds // thirty_seconds + 1)\n",
    "total_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 파일명을 저장할 리스트\n",
    "output_filenames = []\n",
    "\n",
    "for i in range(total_iterations):\n",
    "    if i < total_iterations - 1:\n",
    "        # 30초 단위로 오디오를 분할합니다.\n",
    "        part_of_audio = myaudio[thirty_seconds * i: thirty_seconds * (i + 1)]\n",
    "    else:\n",
    "        # 마지막은 나머지 전체를 분할합니다.\n",
    "        part_of_audio = myaudio[thirty_seconds * i:]\n",
    "\n",
    "    output_filename = (\n",
    "        # 예시: 채용면접_샘플_02-(1).mp3, 채용면접_샘플_02-(2).mp3 ...\n",
    "        f\"{filename[:-4]}-({i+1}).mp3\"\n",
    "    )\n",
    "\n",
    "    # 분할된 오디오를 저장합니다.\n",
    "    part_of_audio.export(output_filename, format=\"mp3\")\n",
    "    output_filenames.append(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과물(파일명) 출력\n",
    "output_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = []\n",
    "\n",
    "for audio_filename in output_filenames:\n",
    "    audio_file = open(audio_filename, \"rb\")  # audio file 을 읽어옵니다.\n",
    "\n",
    "    # transcript 를 생성합니다.\n",
    "    transcript = client.audio.transcriptions.create(\n",
    "        file=audio_file,\n",
    "        model=\"whisper-1\",  # 모델은 whisper-1 을 사용\n",
    "        language=\"ko\",  # 한국어를 사용\n",
    "        response_format=\"text\",  # 결과물은 text 로 출력\n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "    # 생성된 transcript 를 리스트에 추가합니다.\n",
    "    transcripts.append(transcript)\n",
    "\n",
    "# 전체 transcript 출력(리스트를 문자열로 변환)\n",
    "final_output = \"---- 분할 ---- \\n\".join(transcripts)\n",
    "print(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = \"\"\"\n",
    "당신은 채용 담당관입니다.\n",
    "주어진 내용을 바탕으로, 면접자의 긍정적인 면과 부정적인 면을 나누어서 정리해 주세요.\n",
    "결과물은 요약된 불렛포인트로 정리해 주세요.\n",
    "한글로 작성해 주세요.\n",
    "(예시)\n",
    "#긍정적인면\n",
    "- \n",
    "- \n",
    "-\n",
    "#부정정인면\n",
    "-\n",
    "-  \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generate_HR_opinion(temperature, prompt, transcript):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        temperature=temperature,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": transcript},\n",
    "        ],\n",
    "        stream=True,\n",
    "    )\n",
    "    final_answer = []\n",
    "\n",
    "    # 스트림 모드에서는 completion.choices 를 반복문으로 순회\n",
    "    for chunk in response:\n",
    "        # chunk 를 저장\n",
    "        chunk_content = chunk.choices[0].delta.content\n",
    "        # chunk 가 문자열이면 final_answer 에 추가\n",
    "        if isinstance(chunk_content, str):\n",
    "            final_answer.append(chunk_content)\n",
    "            # 토큰 단위로 실시간 답변 출력\n",
    "            print(chunk_content, end=\"\")\n",
    "    return \"\".join(final_answer)\n",
    "\n",
    "\n",
    "hr_opinion = generate_HR_opinion(0, example_prompt, final_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
